---
title: "Probabilistic Modeling - 4"
layout: splash
excerpt: "Variational Autoencoder (VAE) using Pyro"
categories: [Python]
tags: [Pyro, PyTorch, Bayesian Inference, Variational Inference, AutoEncoder, MNIST, Visualization]

---

# 0. Introduction

I have already introduced [VAE](/python/VAE/) and [Pyro](/python/pyro_1/). VAEs can be summarized as the following figure.

<center><img src="/assets/figures/blog/VAE_1.png" width="1000" ></center>

In this blog, I will use `Pyro` to construct a VAE model for the famous MNIST dataset and use (SVI) stochastic variational inference to train the model. I will use the following network structure as in the [previous blog](/python/VAE/).

<center><img src="/assets/figures/blog/VAE_CNN.png" width="1000" ></center>

# 1. Process data

I will use the version of `MNIST` provided by `torchvision`. 

```python
import torch
import torchvision
import torchvision.transforms as transforms
# using transforms.ToTensor() to convert from [0,255] to [0.0,1.0]
transform = transforms.Compose([transforms.ToTensor()])
# I will only use the train set.
trainset = torchvision.datasets.MNIST(root='./data', train=True,download=True, transform=transform)
trainloader = torch.utils.data.DataLoader(trainset, batch_size=128,shuffle=True)
```


# 2. Model

A VAE consists of two parts: a decoder and an encoder. I will use PyTorch to construct both of them.

## 2.1 Decoder and Encoder

The structures of decoder and encoder are described in the figure above.
```python
import torch.nn as nn
class Decoder(nn.Module):
    def __init__(self):
        super(Decoder, self).__init__()
        self.fc1 = nn.Linear(2, 6272)
        self.conv1 = nn.ConvTranspose2d(32, 32, 3,2,padding=1,output_padding=1)
        self.conv2 = nn.Conv2d(32, 1, 3, padding=1)
    def forward(self, z):
        z = self.fc1(z)                         # (,2) => (,6272)
        z = z.view(-1,32,14,14)                 # (,6272) => (,32,14,14)
        z = torch.relu(self.conv1(z))           # (,32,14,14,) => (,32,28,28)
        loc_img = torch.sigmoid(self.conv2(z))  # (,32,28,28) => (,1,28,28)
        return loc_img

class Encoder(nn.Module):
    def __init__(self):
        super(Encoder, self).__init__()
        self.conv1 = nn.Conv2d(1, 16, 3, padding=1)
        self.conv2 = nn.Conv2d(16, 32, 3, 2, padding=1)
        self.conv3 = nn.Conv2d(32, 32, 3, padding=1)
        self.fc1 = nn.Linear(6272, 32)
        self.fc21 = nn.Linear(32, 2)
        self.fc22 = nn.Linear(32, 2)

    def forward(self, x):
        x = torch.relu(self.conv1(x))            #(,1,28,28) => (,16,28,28)
        x = torch.relu(self.conv2(x))            #(,1,28,28) => (,32,14,14)
        x = torch.relu(self.conv3(x))            #(,32,14,14) => (,32,14,14)
        x = x.view(-1,6272)                      #(,32,14,14) => (,6272)
        x = torch.relu(self.fc1(x))
        # mean and std
        z_loc = self.fc21(x)
        z_scale = torch.exp(self.fc22(x))
        return z_loc, z_scale
```

## 2.2 VAE

Now the `VAE` class below contains a `.model()` method and a `.guide()` method, which are used in our `SVI` object.

```python
import pyro
import pyro.distributions as dist
class VAE(nn.Module):
    def __init__(self):
        super(VAE, self).__init__()
        # create the encoder and decoder networks
        self.encoder = Encoder()
        self.decoder = Decoder()

    # define the model
    def model(self, x):
        # register PyTorch module `decoder` with Pyro
        pyro.module("decoder", self.decoder)
        with pyro.plate("data", x.shape[0]):
            # mean and std for prior p(z)
            z_loc = x.new_zeros(torch.Size((x.shape[0], 2)))
            z_scale = x.new_ones(torch.Size((x.shape[0], 2)))
            # sample from prior
            z = pyro.sample("latent", dist.Normal(z_loc, z_scale).to_event(1))
            # decode the latent code z
            loc_img = self.decoder.forward(z)
            # score against actual images
            # among (128,1,28,28), the last 3 should be event_shape, only the first one is batch_shape
            pyro.sample("obs", dist.Bernoulli(loc_img).to_event(3), obs=x)

    # define the guide
    def guide(self, x):
        # register PyTorch module `encoder` with Pyro
        pyro.module("encoder", self.encoder)
        with pyro.plate("data", x.shape[0]):
            z_loc, z_scale = self.encoder.forward(x)
            pyro.sample("latent", dist.Normal(z_loc, z_scale).to_event(1))

    # define a helper function for reconstructing images
    def reconstruct_img(self, x):
        # encode image x
        z_loc, z_scale = self.encoder(x)
        # sample in latent space
        z = dist.Normal(z_loc, z_scale).sample()
        # decode the image (note we don't sample in image space)
        loc_img = self.decoder(z)
        return loc_img
```

# 3. Variational inference using Pyro

The variational inference using Pyro for VAE is similar to the one for Bayesian linear regression in the [previous blog](/python/pyro_1/).

```python
from pyro.infer import SVI, Trace_ELBO
from pyro.optim import Adam
import time

pyro.clear_param_store()
# instantiate a VAE model
vae = VAE()
# optimizer
optimizer = Adam({"lr": 1.0e-3})
# SVI using Trace_ELBO as before
svi = SVI(vae.model, vae.guide, optimizer, loss=Trace_ELBO())
# record losses
train_elbo = []
# train for 10 epochs
for epoch in range(10):
    start = time.time()
    epoch_loss = 0.
    # batch training
    for x, _ in trainloader:
        # update parameters (the gradient step on the loss function)
        epoch_loss += svi.step(x)
    normalizer_train = len(trainloader.dataset)
    total_epoch_loss_train = epoch_loss / normalizer_train
    train_elbo.append(total_epoch_loss_train)
    end = time.time()
    print("epoch: {}\tELBO_loss: {}".format(epoch,total_epoch_loss_train))
    print("time used: {}".format(end-start))
```
```
epoch: 0	ELBO_loss: 210.26156830072205
time used: 156.42615294456482
epoch: 1	ELBO_loss: 175.43245768229167
time used: 156.140851020813
epoch: 2	ELBO_loss: 169.59417425689696
time used: 172.96056485176086
epoch: 3	ELBO_loss: 165.59167473983766
time used: 155.32647013664246
epoch: 4	ELBO_loss: 162.71688343811036
time used: 155.66433215141296
epoch: 5	ELBO_loss: 160.5028678738912
time used: 156.58725881576538
epoch: 6	ELBO_loss: 158.8079438852946
time used: 161.19263577461243
epoch: 7	ELBO_loss: 157.49121241455077
time used: 173.25388598442078
epoch: 8	ELBO_loss: 156.4635259994507
time used: 164.37772917747498
epoch: 9	ELBO_loss: 155.58570947723388
time used: 166.6157660484314
```

# 4. Visualization

Now let's take a grid over 2 dimensional space for the latent vector `z`, and decode it using the decoder part of the VAE trained above. 
```python
k = 30
import scipy.stats as stats
grid_x = stats.norm.ppf(np.linspace(0.01, 0.99, k))
#random latent vector
fig,axes = plt.subplots(k,k,figsize=(10,10))
for i in range(k**2):
    random_image = vae.decoder(torch.tensor([grid_x[i%k], grid_x[i//k]]))
    axes.flatten()[i].axis('off')
    axes.flatten()[i].imshow(random_image.detach().numpy().reshape(28,28),cmap='gray');
```

<center><img src="/assets/figures/pyro/2_decode.png" width="1000" ></center>

We can see that the above decoded images here are much better than those below, which are decoded by VAE trained using Keras.

<center><img src="/assets/figures/blog/VAE_grid_plot.png" width="1000" ></center>



