---
title: PyTorch (part 3)
subtitle: test
author: Ding Ma
layout: post
categories: [blog]
---

<span style="font-weight:bold;font-size:36px">0. Introduction</span>

In this blog, I will introduce 2 different methods to create a convolutional neural network (CNN) model using `PyTorch`, one by using `torch.nn.Sequential` (similar to Keras Sequential Model) and the other by inheriting from `torch.nn.Module`(similar to Keras functional API).

---
<span style="font-weight:bold;font-size:36px">1. Dataset</span>

We will use the famous MNIST dataset to train the CNN. MNIST is available in `torchvision.datasets`, and we will load it using `torch.utils.data.DataLoader` with `batch_size = 128`.
```python
import torch
import torchvision
import torchvision.transforms as transforms
# transform datasets into Tensor
transform = transforms.Compose([transforms.ToTensor()])
# load train set
trainset = torchvision.datasets.MNIST(root='./data', train=True,download=True, transform=transform)
# set batch_size = 128, and shuffle the data
trainloader = torch.utils.data.DataLoader(trainset, batch_size=128,shuffle=True)
# load train set
testset = torchvision.datasets.MNIST(root='./data', train=False,download=True, transform=transform)
# set batch_size = 128
testloader = torch.utils.data.DataLoader(testset, batch_size=128,shuffle=False)
```
---
<span style="font-weight:bold;font-size:36px">2. Define Model Using `torch.nn.Sequential`</span>

Building a neural network model using `torch.nn.Sequential` is quite similar to `keras.models.Sequential`.
```python
import torch.nn as nn
# define the model
model1 = nn.Sequential(
    nn.Conv2d(1,8,3),nn.ReLU(),nn.MaxPool2d((2,2)),
    nn.Conv2d(8,16,3),nn.ReLU(),nn.MaxPool2d((2,2)),
    nn.Flatten(),
    nn.Linear(5*5*16,64),nn.ReLU(),
    nn.Linear(64,32),nn.ReLU(),
    nn.Linear(32,10))
import torch.optim as optim
# use CrossEntropyLoss here since we don't apply softmax for the last layer
criterion = nn.CrossEntropyLoss(reduction='mean')
# choose RMSprop optimizer
optimizer = optim.RMSprop(model1.parameters(),lr=0.001,momentum=0.9)
```
Training CNN is the same as what I did in the [<span style="color:blue">last blog</span>](https://dingma129.github.io/blog/2019/08/15/PyTorch_2.html) when training a linear regression model.
```python
# train the model for 10 epochs
for epoch in range(10):  
    # reset loss for each epoch
    running_loss = 0.0
    for i, data in enumerate(trainloader):
        # get the inputs; data is a list of [inputs, labels]
        inputs, labels = data
        # reset parameter gradients
        optimizer.zero_grad()
        # forward propagation
        outputs = model1(inputs)
        loss = criterion(outputs, labels)
        # backward propagation
        loss.backward()
        # perform a single optimization step
        optimizer.step()
        # add batch loss to running_loss of current epoch
        running_loss += loss.item()
    # print statistics
    print('{}\tloss:\t{:.4f}'.format(epoch + 1, running_loss / (i+1)))

# 1	loss:	0.2298
# 2	loss:	0.0815
# 3	loss:	0.0670
# 4	loss:	0.0576
# 5	loss:	0.0518
# 6	loss:	0.0484
# 7	loss:	0.0480
# 8	loss:	0.0440
# 9	loss:	0.0435
# 10	loss:	0.0431
# Finished Training
```
---
<span style="font-weight:bold;font-size:36px">3. Define Model by Inheriting from `torch.nn.Module`</span>

By inheriting from `torch.nn.Module`, we can define a model functionally as in Keras functional API.
```python
import torch.nn as nn
import torch.nn.functional as F
# channel first
class Net(nn.Module):
    def __init__(self):
        super(Net,self).__init__()
        # layers
        self.conv1 = nn.Conv2d(1,8,3)   # (1,28,28) => (8,26,26)
        self.conv2 = nn.Conv2d(8,16,3)  # (8,13,13) => (16,11,11)
        self.fc1 = nn.Linear(5*5*16,64)
        self.fc2 = nn.Linear(64,32)
        self.fc3 = nn.Linear(32,10) 
    def forward(self,x):
        # forward propagation
        x = F.max_pool2d(F.relu(self.conv1(x)),(2,2))
        x = F.max_pool2d(F.relu(self.conv2(x)),(2,2))
        # flatten
        x = x.view(-1, torch.numel(x[0]))
        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        x = self.fc3(x)
        return x
model2 = Net()
# use the same code for training
# 1	loss:	0.2158
# 2	loss:	0.0795
# 3	loss:	0.0644
# 4	loss:	0.0553
# 5	loss:	0.0502
# 6	loss:	0.0440
# 7	loss:	0.0441
# 8	loss:	0.0391
# 9	loss:	0.0380
# 10	loss:	0.0359
# Finished Training
```
---
<span style="font-weight:bold;font-size:36px">4. Comparison</span>

* `nn.Sequential` is similar to `keras.models.Sequential`, and the structure of layers can only be linear;
* `nn.Module`is similar to Keras' functional API `keras.models.Model`, and the structure of layers can be any (not necessary linear).