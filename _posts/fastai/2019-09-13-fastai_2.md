---
title: "FastAI - 2"
layout: splash
excerpt: "CNN on MNIST"
categories: [Python]
tags: [PyTorch, FastAI, CNN, Classification, MNIST, TensorBoard, Transfer Learning, ResNet]
---

# 0. Introduction

In this blog, I will introduce how to use `fastai` library to train a CNN on the famous MNIST dataset. The versions of the packages when I am writting this blog now is as follows:
```
fastai.__version__ == 1.0.57
torch.__version__ == 1.1.0
```

First we will need to import necessary libraries for this blog.
```python
# a lot of libraries like torch/plt has already been included in fastai
from fastai import *
# we are dealing with images, so we will use fastai.vision
from fastai.vision import *
from fastai.callbacks.tensorboard import *
```

# 1. Load dataset

## 1.1 Download data

The `URLs` module in `fastai.vision` contains urls of a lot of famous datasets. We will use MNIST in this blog.

```python
URLs.MNIST
# 'https://s3.amazonaws.com/fast-ai-imageclas/mnist_png'
```

We can download a dataset using the `untar_data` method.
```python
mnist = untar_data(URLs.MNIST)
# the path of downloaded dataset
mnist
# PosixPath('/root/.fastai/data/mnist_png')
```

Let's first check the folder to see how data is stored.
```python
!ls /root/.fastai/data/mnist_png/
testing  training
# we have a folder for training data and a folder for testing data
```

## 1.2 Load data as `ImageDataBunch`

Before any work can be done using `fastai`, a dataset needs to be converted into a `DataBunch` object, and in the case of the computer vision data - specifically into an `ImageDataBunch` subclass. You probably don't want to initialize it using `ImageDataBunch` directly, but one of the factory methods instead. The most useful two are listed below:
1. `ImageDataBunch.from_folder` if the dataset looks something like this (the test folder is optional)
```
path\
    train\
        clas1\
        clas2\
        ...
    valid\
        clas1\
        clas2\
        ...
    test\
```
2. `ImageDataBunch.from_csv` if the dataset looks something like this
```
path\
    train\
    test\
    labels.csv
```

When loading a dataset using the above method, you can speficy the transforms that you want to apply to the data. In particular, `size` and `resize_method` can be used directly as `kwargs` of the factory methods. For example, the following code will load dataset as an `ImageDataBunch` object from some `path` with some basic transforms on the training set and resize (in particular, squish instead of crop) the picture size into 32 x 32.
```python
# example
ImageDataBunch.from_folder(
    path,  # path of the data
    ds_tfms=(get_transforms(),[]),  # apply transforms to train data only, get_transforms() provides a lot of basic transforms
    train="train",   # subfolder name for train data
    valid_pct = 0.2, # using 20% training data as validation
    test="test"      # subfolder name for test data
    ).normalize(.normalize(cifar_stats)) # normalize data using cifar_stats
```

In particular, for our MNIST dataset, I will use the following code to load the dataset as an `ImageDataBunch` object.
```python
# apply no transforms, 20% train data used as validation data, normalize using mnist_stats, batch_size = 128
data = ImageDataBunch.from_folder(mnist,ds_tfms=([],[]),train="training", valid_pct = 0.2, test="testing",bs=128).normalize(mnist_stats)
```

## 1.3 Data at a glance

We can use `show_batch` to visualize some examples of images.
```python
data.show_batch(rows=5,figsize=(6,6))  # returns 5x5 images
```
<center><img src="/assets/figures/fastai/2_glance.png" width="600" ></center>
We can see the batch_size is `128`.
```python
# batch_size = 128
data.train_dl.batch_size
# batch_shape = (128,3,28,28)
data.one_batch()[0].shape    # [0]: X, [1]: y
```


# 2. Train model

`basic_train` wraps together the data (in a `DataBunch` object) with a `PyTorch` model to define a `Learner` object. Here the basic training loop is defined for the `fit` method. 

For computer vision data, `vision.learner` is the module that defines the `cnn_learner` method, to easily get a model suitable for transfer learning. Transfer learning is a technique where you use a model trained on a very large dataset (usually `ImageNet` in computer vision) and then adapt it to your own dataset.

In practice, you need to **change the last part** (which is called the head of the model) of your model to be adapted to your own number of classes. In transfer learning we will **keep all the convolutional layers** (called the body of the model) with their weights pretrained on `ImageNet` but will **define a new head** initialized randomly. 

The training usually contains two steps:
1. freeze the body weights and only train the head
2. unfreeze the layers of the body and fine-tune the whole model

The complete list of available pretrained vision models can be found [here](https://docs.fast.ai/vision.models.html). I will use `ResNet` with 18 layers here.

```python
# define a cnn_learner
learn = cnn_learner(data, models.resnet18, metrics=accuracy)
# train it for 5 epochs
learn.fit(5,0.001)
```
<center><img src="/assets/figures/fastai/2_train.png" width="600" ></center>
In the final section, I will talk about how to include a TensorBoard callback for `Learner`.

To save the model, use the `save` method of `Learner`.
```python
# save model parameters
learn.save("/content/drive/My Drive/model/MNIST1st")
```

# 3. Prediction

To make predictions, we simply use the following three methods:
1. `.predict()`: for single `Image`
2. `.get_preds()`: for train/valid/test datas
3. `.pred_batch()`: for one batch

Let's look at the `get_preds` method here. After specifying `ds_type`, it will return two tensors: predictions and true_labels.

```python
# returns two tensors, predictions and true_labels
learn.get_preds(ds_type=DatasetType.Train)   # train
learn.get_preds(ds_type=DatasetType.Valid)   # validation
learn.get_preds(ds_type=DatasetType.Test)    # test
```

# 4. Evaluation

## 4.1 Evaluate using metrics

We can easily evalute a `Learner` using any built-in metric. For example, we can use `accuracy` as follows.
```python
accuracy(*learn.get_preds(ds_type=DatasetType.Train))
# tensor(0.9923)
accuracy(*learn.get_preds(ds_type=DatasetType.Valid))
# tensor(0.9849)
```

## 4.2 Visualizations

During the training, a `Learner` creates a `Recorder` object automatically. This `Recorder` object contains a lot of plotting methods.

1. `plot_lr()` plots learning rates vesus iterations. In our case, the learning rate is constantly `0.001`.
<center><img src="/assets/figures/fastai/2_plotlr.png" width="500" ></center>
2. `plot_losses()` plots losses versus iterations. The train losses are recorded every batch, and the validation losses are recorded every epoch.
<center><img src="/assets/figures/fastai/2_plotloss.png" width="500" ></center>
3. `plot_losses()` plots metrics versus iterations. The train metrics are recorded every batch. In our case, the only metric is `accuracy`.
<center><img src="/assets/figures/fastai/2_plotmetric.png" width="500" ></center>
The `ClassificationInterpretation` class implements several interpretation methods for classification models. For example, we can use it to plot confusion matrix of a classification problem, or to plot a few samples with largest losses.

```python
preds,y,losses = learn.get_preds(with_loss=True)
# create a ClassificationInterpretation object
interp = ClassificationInterpretation(learn, preds, y, losses)
# plot confusion matrix
interp.plot_confusion_matrix()
# plot top losses examples
interp.plot_top_losses(25, figsize=(9,9))
```

<p>
<img src="/assets/figures/fastai/2_cm.png" width="400" >
<img src="/assets/figures/fastai/2_toploss.png" width="600" >
</p>
We can see that the first two really looks like 9 and 1. Even a human being cannot classify them correctly.

# 5. TensorBoard callback

To use `TensorBoard` callback, we first need to install `tensorboardx`, and import the corresponding methods.
```python
!pip install tensorboardx 
from fastai.callbacks.tensorboard import *
```

When creating the `Learner`, we should include the corresponding callback as follows.
```python
# specify tensorboard directory
project_id = 'mnist'
tboard_path = Path('/content/drive/My Drive/tensorboard/' + project_id)
# include callback_fns for TensorBoard
learn = cnn_learner(data, models.resnet18, metrics=accuracy,
    callback_fns=[partial(LearnerTensorboardWriter,base_dir=tboard_path, name='run_01')])
```

Now after training, we can access TensorBoard using
```
tensorboard --logdir /content/drive/My\ Drive/tensorboard/mnist
```