---
title: PyTorch (part 2)
author: Ding Ma
layout: post
categories: [blog]
---

<span style="font-weight:bold;font-size:36px">0. Introduction</span>

<span style="font-weight:bold;font-size:36px">1. Dataset</span>

```python
import torch
import torchvision
import torchvision.transforms as transforms
# transform datasets into Tensor
transform = transforms.Compose([transforms.ToTensor()])
# load train set
trainset = torchvision.datasets.MNIST(root='./data', train=True,download=True, transform=transform)
# set batch_size = 128, and shuffle the data
trainloader = torch.utils.data.DataLoader(trainset, batch_size=128,shuffle=True)
# load train set
testset = torchvision.datasets.MNIST(root='./data', train=False,download=True, transform=transform)
# set batch_size = 128
testloader = torch.utils.data.DataLoader(testset, batch_size=128,shuffle=False)
```

<span style="font-weight:bold;font-size:36px">2. Define Model Using `torch.nn.Sequential`</span>

```python
import torch.nn as nn
# define the model
model1 = nn.Sequential(
    nn.Conv2d(1,8,3),nn.ReLU(),nn.MaxPool2d((2,2)),
    nn.Conv2d(8,16,3),nn.ReLU(),nn.MaxPool2d((2,2)),
    nn.Flatten(),
    nn.Linear(5*5*16,64),nn.ReLU(),
    nn.Linear(64,32),nn.ReLU(),
    nn.Linear(32,10))
import torch.optim as optim
# use CrossEntropyLoss since we don't apply softmax for the last layer
criterion = nn.CrossEntropyLoss(reduction='mean')
# choose RMSprop optimizer
optimizer = optim.RMSprop(model1.parameters(),lr=0.001,momentum=0.9)
```

```python
# train the model for 10 epochs
for epoch in range(10):  
    # reset loss for each epoch
    running_loss = 0.0
    for i, data in enumerate(trainloader):
        # get the inputs; data is a list of [inputs, labels]
        inputs, labels = data
        # reset parameter gradients
        optimizer.zero_grad()
        # forward propagation
        outputs = model1(inputs)
        loss = criterion(outputs, labels)
        # backward propagation
        loss.backward()
        # perform a single optimization step
        optimizer.step()
        # accumulate loss for current minibatch
        running_loss += loss.item()
    # print statistics
    print('{}\tloss:\t{:.4f}'.format(epoch + 1, running_loss / (i+1)))
```
<center><img src="https://dingma129.github.io/assets/figures/pytorch/pytorch_2_model1.png" width="300" ></center>

<span style="font-weight:bold;font-size:36px">3. Define Model Using `torch.nn.Module`</span>

```python
import torch.nn as nn
import torch.nn.functional as F
# channel first
class Net(nn.Module):
    def __init__(self):
        super(Net,self).__init__()
        # layers
        self.conv1 = nn.Conv2d(1,8,3)   # (1,28,28) => (8,26,26)
        self.conv2 = nn.Conv2d(8,16,3)  # (8,13,13) => (16,11,11)
        self.fc1 = nn.Linear(5*5*16,64)
        self.fc2 = nn.Linear(64,32)
        self.fc3 = nn.Linear(32,10) 
    def forward(self,x):
        # forward propagation
        x = F.max_pool2d(F.relu(self.conv1(x)),(2,2))
        x = F.max_pool2d(F.relu(self.conv2(x)),(2,2))
        x = x.view(-1, torch.prod(torch.tensor(x.size()[1:])))
        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        x = self.fc3(x)
        return x
model2 = Net()
```

training as above
<center><img src="https://dingma129.github.io/assets/figures/pytorch/pytorch_2_model2.png" width="300" ></center>