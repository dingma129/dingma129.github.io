---
title: "Kaggle - 2"
layout: splash
excerpt: "Competition: New York City Taxi Fare Prediction"
categories: [Python]
tags: [Kaggle, Regression]
---

# 0. Introduction

In this blog, I will discuss the Kaggle competition: [New York City Taxi Fare Prediction](https://www.kaggle.com/c/new-york-city-taxi-fare-prediction). 

```python
import pandas as pd
import seaborn as sns
```

# 1. Data

## 1.1 Load and preview data
The training data contains about 55M rows, and the data is well-shuffled. In this blog, I will only use the the first 50K rows only.

Let's first look at the dataset.

```python
df = pd.read_csv("data/train.csv",nrows=50000,index_col=0,parse_dates=["pickup_datetime"])
df.reset_index(drop=True, inplace=True)
df.head()
```
<center><img src="/assets/figures/kaggle/2_data.png" width="1000" ></center>
It contains pickup time, pickup/dropoff GPS, number of passengers and fare amount.

## 1.2 Clean data

There are some abnormal rows (for example, 0 passanger counts , 0 fare amount or meanless longitude/latitude). I will first clean the data by removing abnormal rows. Also I will extract `year`, `month`, `day of week` and `hour` information from the `pickup_datetime` column

```python
# extract some time information
df["year"] = df["pickup_datetime"].apply(lambda x: x.year)
df["month"] = df["pickup_datetime"].apply(lambda x: x.month)
df["dayofweek"] = df["pickup_datetime"].apply(lambda x: pd.datetime.isoweekday(x))
df["hour"] = df["pickup_datetime"].apply(lambda x: x.hour)
# keep only 2009-2014
df = df[df["year"] < 2015]
# remove abnormal rows
df = df[df["passenger_count"] > 0]
df = df[df["fare_amount"] > 0]
df = df[(-74.51 < df["pickup_longitude"]) & (df["pickup_longitude"] < -73.29) & (40.39 < df["pickup_latitude"]) &(df["pickup_latitude"] < 41.21)]
df = df[(-74.51 < df["dropoff_longitude"]) & (df["dropoff_longitude"] < -73.29) & (40.39 < df["dropoff_latitude"]) &(df["dropoff_latitude"] < 41.21)]
df.head()
```
<center><img src="/assets/figures/kaggle/2_data_cleaned.png" width="1000" ></center>
## 1.3 Simple feature engineering

I will first create two features corresponding to whether a date is a businessday / holiday.

```python
# holiday list
from pandas.tseries.holiday import USFederalHolidayCalendar as calendar
cal = calendar()
holidays = cal.holidays(start='1/1/2009', end='1/1/2015')
# set of all business days
businessDays = set(pd.datetime.date(d) for d in pd.bdate_range(start='1/1/2009', end='1/1/2015'))
# create is_businessday variable
df["is_businessday"] = df["pickup_datetime"].apply(lambda x: 1 if pd.datetime.date(x) in businessDays else 0)
# create is_holiday variable
df["is_holiday"] = df["pickup_datetime"].apply(lambda x: 1 if pd.datetime.date(x) in holidays else 0)
```

# 2. Visualization

## 2.1 counts and average fares over time

Let's first look at how does the data distribute over year, month, day of week and hour.
<center><img src="/assets/figures/kaggle/2_count.png" width="1000" ></center>
From the above figure, we can clearly see that there are less rides between <u><b>1:00 - 6:59</b></u>.

On the other hand, the average fare is much higher between <u><b>4:00 - 5:59</b></u>
<center><img src="/assets/figures/kaggle/2_avg.png" width="1000" ></center>
Using Gaussian kernel density estimation, we can also see the obvious difference between <u><b>4:00 - 5:59</b></u> and other time.
<center><img src="/assets/figures/kaggle/2_kde_time.png" width="600" ></center>
## 2.2 what about location?

Are there any places which are very different from others?

To answer this question, let's first plot the data on a map. We first remove some abnormal data, either the pickup and dropoff locations are too close (less than around 11 meters) or too far (more than around 111 kilometers).

```python
# remove abnormal data
dfplot = df[(np.abs(df["pickup_latitude"]-df["dropoff_latitude"]) + np.abs(df["pickup_longitude"]-df["dropoff_longitude"])>0.0001) 
            & (np.abs(df["pickup_latitude"]-df["dropoff_latitude"]) + np.abs(df["pickup_longitude"]-df["dropoff_longitude"])<1)]
# round GPS to 2 decimals   
dfGPS = dfplot
dfGPS["from_lon"] = np.round(dfGPS["pickup_longitude"],2)
dfGPS["from_lat"] = np.round(dfGPS["pickup_latitude"],2)
dfGPS["to_lon"] = np.round(dfGPS["dropoff_longitude"],2)
dfGPS["to_lat"] = np.round(dfGPS["dropoff_latitude"],2)
```
Using heatmap, we can see that most trips starts and ends in Manhattan, JFK airport or LGA airport.
<center><img src="/assets/figures/kaggle/2_heatmap_count.png" width="1000" ></center>
We can also visualize the average fare by pickup and dropoff locations. We can see that if the pickup/dropoff location is in Manhattan, the average fare would be lower. While if the pickup location is in JFK airport or the dropoff location is not in Manhattan, the average fare would be much higher. 
<center><img src="/assets/figures/kaggle/2_heatmap_fare.png" width="1000" ></center>
By hour, the average fare is always high if the pickup or dropoff location is JFK. We can also seen that the pickup locations are mainly in Manhattan, while the dropoff locations are widely spreaded.
<center>
  <div class="row">
    <div class="column">
      <img src="/assets/figures/kaggle/2_heatmap_from.gif" width="500" >
      <img src="/assets/figures/kaggle/2_heatmap_to.gif" width="500" >
    </div>
    <div class="column">
      <img src="/assets/figures/kaggle/2_heatmap_to.gif" width="500" >
    </div>
  </div>
</center>














